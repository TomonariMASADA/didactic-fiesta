> The conversion of internal states into language and back is the essential function of LLMs, embedded in their architecture and training. [^1]

人間はなすことができていて、人工的な知能がまだなすことができていないものは、情報の粒度の再調整である。

情報の粒度の再調整は、例えば、人間がconventionを必要とすることに対応しているし、また、人間がdeductionとinductionだけではなくabductionも必要とすることに対応している。人間は、上の引用が述べているようなback and forthだけではなく、abductionも必要とすることに対応している。

テキストデータであれば、語彙の再設定が、情報の粒度の再調整に対応する。言語モデルが、必要に応じて、サブワードの集合を設定し直す、といった状況を考えればよい。

画像データであれば、一つのピクセルにどれだけの視覚情報を収めるかの再設定が、情報の粒度の再調整に対応する。この程度の再調整であれば、警戒の姿勢を取って一点を注視している猫ですら行っている。

機械学習の世界で言えば、情報の粒度の再調整は、訓練データ集合を一から作り直すことに対応する。これを計算機自身が行うことが、人間の知能で言えば、abductionを行うことに対応している。

abductionは、様々なスケールで行われる。ぼんやりとしか見ていなかった対象を、瞼を大きく開いてちゃんと見直すといったスケールから、新しい科学的な発明まで、様々なスケールで行われる。いずれも、いわば情報の粒度の再調整が行われている。

情報の粒度が変わると、トークンの切れ目、ピクセルの切れ目が変わる。だから、現在の人工的な知能にとっては、データセットの作り直しを意味し、すべてをやり直すことになる。

動物の場合、しばしば、姿勢を変えることによって、情報の粒度の再調整が行われる。つまり、身体を持つことが、情報の粒度の再調整の一つの手段である。しかし、身体を持つことは、おそらく、情報の粒度の再調整を実現することにとって、必要条件ではあっても、十分条件ではない。つまり、人工的な知能をロボット化しさえすればよいのかどうかは、分からない。

情報の粒度の再調整は、ここでの議論で言えば、想起に対応する。例えば、いつも使っていた道具が使えなくなると、情報の粒度の再調整を行う。そして、道具が問題なく使えている間に、ひたすら同じ情報の粒度を繰り返し再生産することは、retentionに対応している。

ひたすら同じ情報の粒度を繰り返し再生産することとは、同じindifferenceがそのまま維持されていることである。

（なお、indifferenceをinvarianceと呼んでもいいかもしれないが、invarianceという言葉は数学的なconnotationが強すぎるので、避けている。）

[^1] Piantasodi, Steven T. and Hill, Felix. Meaning without reference in large language models. [https://arxiv.org/abs/2208.02957](https://arxiv.org/abs/2208.02957)




